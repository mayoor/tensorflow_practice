{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "slim  = tf.contrib.slim\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nets import inception\n",
    "from preprocessing import inception_preprocessing\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from datasets import imagenet\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    }
   ],
   "source": [
    "print (inception.inception_v4.default_image_size)\n",
    "image_size = inception.inception_v4.default_image_size\n",
    "checkpoints_dir = '/Users/mayoor/dev/logistic_regression/inception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_regression_head(bb_net,dropout_keep_prob=0.8):\n",
    "    dropout_keep_prob=0.8\n",
    "    with tf.variable_scope('BB_Logits'):\n",
    "        # 8 x 8 x 1536\n",
    "        net = slim.avg_pool2d(bb_net, bb_net.get_shape()[1:3], padding='VALID',\n",
    "                            scope='AvgPool_1a_bb')\n",
    "        # 1 x 1 x 1536\n",
    "        net = slim.dropout(net, dropout_keep_prob, scope='Dropout_1b_bb')\n",
    "        net = slim.flatten(net, scope='PreLogitsFlatten_bb')\n",
    "        net = slim.fully_connected(net, 4, activation_fn=None,\n",
    "                                    scope='BB_Logits')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(reader_queue):\n",
    "    label = reader_queue[1]\n",
    "    image_string = tf.read_file(reader_queue[0])\n",
    "    print (image_string)\n",
    "    print (label)\n",
    "    label_oh = tf.one_hot(label, depth=4)\n",
    "    image = tf.image.decode_image(image_string, channels=3)\n",
    "    processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=True)\n",
    "    processed_images  = tf.expand_dims(processed_image, 0)\n",
    "    \n",
    "    return tf.reshape(processed_images,[image_size,image_size,3]), label_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_bnd(reader_queue):\n",
    "    label = reader_queue[1]\n",
    "    image_string = tf.read_file(reader_queue[0])\n",
    "\n",
    "    label_oh = label\n",
    "    image = tf.image.decode_image(image_string, channels=3)\n",
    "    processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=True)\n",
    "    processed_images  = tf.expand_dims(processed_image, 0)\n",
    "    \n",
    "    return tf.reshape(processed_images,[image_size,image_size,3]), label_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getDataSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7edba6b054f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'super_hero_meta.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreader_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_input_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'super_heros'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batman'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     images, labels = tf.train.shuffle_batch(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getDataSet' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    labels = json.loads(open('super_hero_meta.json','r').read())\n",
    "    reader_queue = tf.train.string_input_producer(getDataSet('super_heros')['batman'])\n",
    "    image, label = load_data(reader_queue, labels)\n",
    "    images, labels = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=10000)\n",
    "    with tf.Session() as sess:\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        val = sess.run(k)\n",
    "        print (val)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllFiles(root_folder, data_file):\n",
    "    data_js = os.path.join(root_folder, data_file)\n",
    "    bnd_boxes = []\n",
    "    image_files = []\n",
    "    with open(data_js,'r') as df:\n",
    "        data_map = json.loads(df.read())\n",
    "        all_data = data_map['images']\n",
    "        for rec in all_data:\n",
    "            image_files.append(os.path.join(root_folder, rec['location']))\n",
    "            bnd_boxes.append(np.array([float(rec['bindbox']['xmin']),float(rec['bindbox']['ymin']),float(rec['bindbox']['xmax']),float(rec['bindbox']['ymax'])]))\n",
    "    return image_files, bnd_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataSet(root_folder, data_file):\n",
    "    data = defaultdict(list)\n",
    "    for (dirpath, dirnames, filenames) in walk(root_folder):\n",
    "        for image in filenames:\n",
    "            label = dirpath[dirpath.index('/')+1:]\n",
    "            image_file = os.path.join(dirpath,image)\n",
    "            data[label].append(image_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_init_fn():\n",
    "    \"\"\"Returns a function run by the chief worker to warm-start the training.\"\"\"\n",
    "    checkpoint_exclude_scopes=[\"InceptionV4/Logits\", \"InceptionV4/AuxLogits\"]\n",
    "    \n",
    "    exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "    variables_to_restore = ['BB_Logits']\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "\n",
    "    #variables_to_restore = []\n",
    "    #for var in slim.get_model_variables():\n",
    "    #    variables_to_restore.append(var)\n",
    "\n",
    "    return slim.assign_from_checkpoint_fn(\n",
    "      os.path.join(checkpoints_dir, 'inception_v4.ckpt'),\n",
    "      variables_to_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_init_fn():\n",
    "    return slim.assign_from_checkpoint_fn(\n",
    "        os.path.join(checkpoints_dir, 'inception_v4.ckpt'),\n",
    "        slim.get_model_variables('InceptionV4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8966, 4)\n",
      "(10, 299, 299, 3)\n",
      "Added regression head.....\n",
      "Inception weights loaded.....\n",
      "Tensor(\"BB_Logits/BB_Logits/BiasAdd:0\", shape=(10, 4), dtype=float32) Tensor(\"shuffle_batch:1\", shape=(10, 4), dtype=float64)\n",
      "WARNING:tensorflow:From <ipython-input-37-3dca1b034b3c>:36: mean_pairwise_squared_error (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.mean_pairwise_squared_error instead. Note that the order of the predictions and labels arguments was changed.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:620: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From <ipython-input-37-3dca1b034b3c>:38: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "Starting training..\n",
      "INFO:tensorflow:Restoring parameters from /Users/mayoor/dev/logistic_regression/inception/inception_v4.ckpt\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path incep_bb/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global step 1: loss = 347152.9375 (125.713 sec/step)\n",
      "INFO:tensorflow:global step 2: loss = 42179656.0000 (17.104 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "INFO:tensorflow:Recording summary at step 2.\n",
      "INFO:tensorflow:global_step/sec: 0.0199981\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "with tf.Graph().as_default():\n",
    "    #labels = json.loads(open('super_hero_meta.json','r').read())\n",
    "    #reverse_labels = json.loads(open('super_hero_meta_reverse.json','r').read())\n",
    "    #reader_queue = tf.train.string_input_producer(getAllFiles('super_heros'))\n",
    "    i, bnd = getAllFiles('/Users/mayoor/dev/slim/VOCtrainval_11-May-2012/VOCdevkit/VOC2012', 'voc_annot.json')\n",
    "    igs = tf.convert_to_tensor(i, dtype=tf.string)\n",
    "    bnds = tf.stack(bnd)\n",
    "    print (bnds.get_shape())\n",
    "    reader_queue = tf.train.slice_input_producer([igs,bnds],\n",
    "                                            num_epochs=2,\n",
    "                                            shuffle=True)\n",
    "    image, label = load_data_bnd(reader_queue)\n",
    "    processed_images, bb_target = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        capacity=50000,\n",
    "        min_after_dequeue=10000)\n",
    "    \n",
    "    print(processed_images.get_shape())\n",
    "    # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "    with slim.arg_scope(inception.inception_v4_arg_scope()):\n",
    "        logits, endpoints = inception.inception_v4(processed_images, num_classes=1001, is_training=True)\n",
    "        bb_net = endpoints['Mixed_7d']\n",
    "    \n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    bb_logits = add_regression_head(bb_net)\n",
    "    print('Added regression head.....')\n",
    "\n",
    "    #init_fn, init_dict = slim.assign_from_checkpoint(\n",
    "    #    os.path.join(checkpoints_dir, 'inception_v4.ckpt'),\n",
    "    #    slim.get_model_variables('InceptionV4'))\n",
    "    print('Inception weights loaded.....')\n",
    "    \n",
    "    print (bb_logits, bb_target)\n",
    "    loss = slim.losses.mean_pairwise_squared_error(bb_logits, bb_target)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    total_loss = slim.losses.get_total_loss()\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "    logdir = 'incep_bb'\n",
    "    print (\"Starting training..\")\n",
    "    slim.learning.train(train_op,logdir,init_fn=get_new_init_fn(),number_of_steps=2,save_summaries_secs=100,save_interval_secs=600)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
